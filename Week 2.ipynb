{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic regression\n",
    "\n",
    "Here, we will explore the logistic regression model that we covered in class. In good practice though, machine learning development should not start with thinking about the learning algorithm but begin with thinking about the problem, i.e. problem understanding, and then exploring the data. Today, we'll start with the data; in the real world, the problem that needs to be solved will be the starting point.\n",
    "\n",
    "\n",
    "> You can listen here about the data-centric AI movement that encourages the approach of exploring and 'working on' the data (rather than only focusing on the crafting of a machine learning architecture) at the centre of developing a model for a given problem: https://datacentricai.org/blog/opening-remarks/\n",
    "\n"
   ],
   "metadata": {
    "id": "lhcT91UwAajV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data\n",
    "\n",
    "-- This week, we will be using real data instead of generating it randomly like we did last week. Specifically, we will use the Wine dataset. Read more about the dataset here: https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset.\n",
    "\n",
    "\n",
    "-- Here are some prompts to help you find out more about the dataset:\n",
    "\n",
    "*   What type of labels does it have (real continuous or categorical)**?**\n",
    "*   What is the feature dimensionality, i.e. the number of features**?**\n",
    "*   Can you find out how it was collected**?**\n",
    "*   What of how it was labelled**?**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "_p5-W8w2AwG_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data\n",
    "\n",
    "\n",
    "-- You need to load the data before you can get started. Here is documentation about how to load the wine data with the *scikit learn* library:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html\n",
    "\n",
    "\n",
    "-- After you load the data, you can explore the relationships between each individual feature and the labels, e.g. using scatter plots or boxplots.\n",
    "\n",
    "\n",
    "-- Next, you can split the data into training and test sets. You can use this split function: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split. Let's do a 50:50 split first, i.e. take half of the dataset and put in a variable that represents your training set and keep the other half as your test set. Do a random split. What is the distribution of the labels in the training set**?** You can plot the distribution (Hint: You could use a histogram for the case of categorical labels).\n",
    "\n",
    "You can use the code cell below. You will need to complete the code."
   ],
   "metadata": {
    "id": "niqpu-upCGOx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# load wine dataset and get the features and the labels\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "wine_data = load_wine()\n",
    "wine_data_feature_vector = wine_data.data\n",
    "wine_data_label = wine_data.target\n",
    "\n",
    "# randomly split 50/50 into training and test sets\n",
    "training_set_ids = sklearn.model_selection.train_test_split(wine_data,train_size=0.5)\n",
    "test_set_ids = sklearn.model_selection.train_test_split(wine_data,train_size=0.5)\n",
    "training_set_feature_vector = training_set_ids.data\n",
    "training_set_label = training_set_ids.target\n",
    "test_set_feature_vector =  test_set_ids.data\n",
    "test_set_label = test_set_ids.target\n",
    "\n",
    "# show the distribution of the labels in the training set\n",
    "print(wine_data_label)"
   ],
   "metadata": {
    "id": "FipQwcNeDI0A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelling\n",
    "\n",
    "-- Now that you have training and test sets, you can start modelling. Let's start with a logistic regression model. Here is the documentation on how to build a logistic regression model using the *scikit learn* library: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html. Have a look at the parameters of the function for building the model. Which can you relate to the parameters that we considered in class**?**\n",
    "\n",
    "\n",
    "\n",
    "-- Build the model using the training set (you can start with the default parameter settings), then evaluate it using the test set. Just for today, you can use accuracy as the performance metric. You can use the accuracy function in the *scikit learn* library (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html). Compute the overall accuracy. Then, check the accuracy per class. What do you find**?** If you found something unexpected, why do you think that is**?** What happens if you change the 'penalty' parameter, i.e. the regularization parameter, to 'None'**?**\n",
    "\n",
    "You can use the code cell below. You will need to complete the code.\n"
   ],
   "metadata": {
    "id": "vx8zGHSpE_X1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# build the model\n",
    "logistic_regr_model = \n",
    "\n",
    "# evaluate the model\n",
    "test_prediction =\n",
    "\n",
    "overall_accuracy = \n",
    "\n",
    "accuracy_per_class = \n",
    "\n"
   ],
   "metadata": {
    "id": "sETTFPn0HBCL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelling with training and test sets swapped\n",
    "\n",
    "\n",
    "-- Repeat the experiment above but with the training and test sets swapped. Before you run the experiment, check the distribution of the labels in the new training set. Do you find any difference in the performance of the two models**?** If there is any, why do you think there might be a difference**?** And what does that then imply**?**\n",
    "\n",
    "You can use the code cell below. You will need to complete the code"
   ],
   "metadata": {
    "id": "LtnJWKoeIQDj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# swap training and test sets\n",
    "new_training_feature_vector =\n",
    "new_training_label =\n",
    "new_test_feature_vector =\n",
    "new_test_label =\n",
    "\n",
    "# show the distribution of the labels in the training set\n",
    "\n",
    "# build the new model\n",
    "logistic_regr_model_swapped = \n",
    "\n",
    "# evaluate the new model\n",
    "test_prediction_swapped =\n",
    "\n",
    "overall_accuracy_swapped = \n",
    "\n",
    "accuracy_per_class_swapped = \n"
   ],
   "metadata": {
    "id": "_R5jBdwkI47I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing the performance of the logistic regression with other algorithms\n",
    "\n",
    "-- You can build additional models using the kNN and Naive Bayes classifier. You can find the documentations in https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html and https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB for the *scikit learn* library. How do they compare with the performance of the logistic regression**?** \n",
    "\n",
    "-- You can try different values of k for the kNN, recording the accuracy in each case. You can create a plot of accuracy (on the y axis) against k (on the x axis). What do you notice**?**\n",
    "\n",
    "-- Rather than the 50:50 split you used above, you can try an 80:20 split for the logistic regression. What do you find, compared to the 50:50 split**?** And why, if you find any difference**?**\n",
    "\n"
   ],
   "metadata": {
    "id": "UOMlgRBcJkeE"
   }
  }
 ]
}